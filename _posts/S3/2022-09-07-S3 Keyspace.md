---
title: S3 Keyspace
author: J.M
date: 2022-09-07
category: S3
layout: post
---

**[[해당 내용은 AWS 웨비나에 대한 내용을 정리 및 관련 내용을 추가한 글 입니다.]]**

S3를 활용하여 Data Lake를 구축하고 Data를 조회 및 적재를 하다보면 "Slow Down" 이라는 Error를 종종 접할 수 있습니다. 

해당 이슈는 S3에서 제한하는 "초당 요청 수" 를 초과했을 때 발생합니다.

S3에 대한 Data 설계에 따라 해당 이슈를 최소화 및 최적화가 가능합니다.

## 전제 사항

| Request Method  | All Regions               |
| --------------- | ------------------------- |
| GET/HEAD        | 5,500 requests per second |
| PUT/POST/DELETE | 3,500 requests per second |

- 초당 요청은 인덱스 파티션 당 요청입니다
- 접두사 수에는 제한이 없습니다
- 503 Slow Down 오류는 요청 속도를 늦추는 주요 지표입니다

TPS 계산 방법

1. Situation : 단일 Partition에 50% PUT and 50% GET 작업 수행 시

   > 총 TPS : 4,500 TPS
   > (50% * 3,500) + (50% * 5,500) = 1,750 + 2,750 = 4,500 TPS

2. Situation : 단일 Partition에 30% PUT and 70% GET 작업 수행 시

   > 총 TPS : 4,900 TPS Combined TPS
   > (30% * 3,500) + (70% * 5,500) = 1,050 + 3,850 = 4,500 TPS

## S3 Keyspace 설계

S3 Data 조회 시 초당 요청을 늘리는 방법은? ====> "**인덱스를 여러 파티션에 분산**"

인덱스를 분할하는 두 가지 방법

1. Auto partitioning
   - 사용자의 개입 없이 S3 에서 자동으로 수행
   - 시간에 따라 S3 워크로드가 점차 증가할 때 동작
2. Pre partition request
   - 케이스 요청을 통해 수행 가능
   - S3 워크로드가 빠르게 증가할 때 미리 요청하는 것을 권장

### 1. Auto Partitioning

![s3_auto_partitioning_metric](../../../../Images/S3/s3_auto_partitioning_metric.png)

> 상단 지표를 확인하면 지속적인 요청 시 503 Error (Slow Down Issue)가 점차 감소하는 것을 확인할 수 있습니다.
>
> 요청하는 S3 경로에 대해 자동으로 인덱스 파티션을 생성하므로써 Error 케이스가 감소하고 있습니다.

EX) S3 Data 구조가 하단과 같이 구성되어있을 경우

```
test_bucket/
├── partition_test/ 			<===== 요청
    ├── test01/
    │   ├── 20220101/
    │   │   ├── test.csv
    │   ├── 20220102/
    │   │   ├── test.csv
    ├── test02/
    │   ├── 20220101/
    │   │   ├── test.csv
    │   ├── 20220102/
    │   │   ├── test.csv
```

s3://test_bucket/partition_test/ 경로로 Slow Down Issue가 생길 정도로 지속적인 요청이 발생한다면 하단 순서 대로 인덱스 파티션이 생성됩니다.

1. ```
   test_bucket/
   ├── partition_test/
       ├── test01/  				<===== 첫 번째 인덱스 파티션
       │   ├── 20220101/
       │   │   ├── test.csv
       │   ├── 20220102/
       │   │   ├── test.csv
       ├── test02/  				<===== 첫 번째 인덱스 파티션
       │   ├── 20220101/
       │   │   ├── test.csv
       │   ├── 20220102/
       │   │   ├── test.csv
   ```

2. ```
   test_bucket/
   ├── partition_test/
       ├── test01/
       │   ├── 20220101/			<===== 두 번째 인덱스 파티션
       │   │   ├── test.csv
       │   ├── 20220102/			<===== 두 번째 인덱스 파티션
       │   │   ├── test.csv
       ├── test02/
       │   ├── 20220101/			<===== 두 번째 인덱스 파티션
       │   │   ├── test.csv
       │   ├── 20220102/			<===== 두 번째 인덱스 파티션
       │   │   ├── test.csv
   ```

상단 내용처럼 4개의 인덱스 파티션이 발생됩니다.

1. Auto Partitioning을 위해 필요한 Throttling 지속 기간은?

   > 쓰로틀링이 지속되어야하는 시간에 대해서는 알려진 바가 없습니다. Black Box ㅜㅜ
   >
   > 급속도로 오르는 요청에 대해 503 에러가 발생할 수 있고 내부적인 로직에 의해 해당 Case에 대해서 Auto Partitiong이 수행됩니다.

   

2. 파티션 인덱스의 생성 단위는 prefix?

   EX) s3://test_bucket/partition_test/test01, s3://test_bucket/partition_test/test01/2022010

   > 반드시 prefix가 partition의 구분 배치와 동일하지는 않으며, 문자열 기준으로 쪼개지는 경우도 있습니다. 
   >
   > 따라서 정확한 partitioning 을 위해서는 case open을 통해 pre-partitioning을 일부 문자열에 대해 요청이 권장됩니다.

   

3. s3://test_bucket/partition_test/test01/로 지속적인 스로틀링이 발생하면

   - s3://test_bucket/partition_test/test01/20220101/
   - s3://test_bucket/partition_test/test01/20220102

   상위 2가지 prefix 단위로도 파티션이 추가?

   > throttling이 20220101, 20220102에서 각각 발생해야 S3 내부적으로 두 prefix에 대해 각각의 파티션을 자동 생성 할 수 있습니다.
   >
   > 상위 prefix에 요청을 하더라도 하위 prefix까지 throttling이 일어나야 auto partitioning이 가능합니다.

   

### 2. Pre partition request

사용자가 Case Open을 통해 Partition Index 생성 요청을 하여 운영 시에 Slow Down Issue를 사전에 방지하는 방법

EX) S3 Data 구조가 하단과 같이 구성되어있을 경우

```
test_bucket/
├── partition_test/ 			<===== 요청
    ├── test01/
    │   ├── 20220101/
    │   │   ├── test.csv
    │   ├── 20220102/
    │   │   ├── test.csv
    ├── test02/
    │   ├── 20220101/
    │   │   ├── test.csv
    │   ├── 20220102/
    │   │   ├── test.csv
```

요청 :
```
test_bucket/
├── partition_test/
    ├── test01/  				<===== 요청 인덱스 파티션
    │   ├── 20220101/			<===== 요청 인덱스 파티션
    │   │   ├── test.csv
    │   ├── 20220102/			<===== 요청 인덱스 파티션
    │   │   ├── test.csv
    ├── test02/  				<===== 요청 인덱스 파티션
    │   ├── 20220101/			<===== 요청 인덱스 파티션
    │   │   ├── test.csv
    │   ├── 20220102/			<===== 요청 인덱스 파티션
    │   │   ├── test.csv
```



1. Pre partition request에 대한 제약 사항?

   > Pre partitioning 요청에 대해서 제약 사항이 알려진 바는 없으나 너무 많은 prefix에 대한 요청은 내부적으로 거절될 수도 있으므로 요청 시 예상 부하에 대한 건 수치나 자료 등을 함께 첨부하거나 적은 수의 요청을 하는 것이 좋습니다.
   >
   > 또한 S3 서비스팀에게로의 요청을 별도로 AWS 서포트 엔지니어가 내부티켓으로 요청 및 적용하는 시간도 필요하기에 충분한 시간을 두고 요청 하는 것을 권장합니다.



### S3 Partition 최적화

1. 2018년 7 월 이전
   - 접두사 앞에 해시 추가
     - examplebucket/232a 2013 26 05 15 00 00/cust1234234/photo001.jpg
     - examplebucket/232b 2013 26 05 15 00 00/cust1234234/photo002.jpg
       …
     - examplebucket/292a 2013 26 05 15 00 00/cust1234234/photo099.jpg
   - 접두사 앞에 해시를 추가하여 요청이 여러 인덱스 파티션으로 분산
2. 2018년 7 월부터
   - Keyspace에 자연명을 사용할 수 있습니다 버킷의 접두사 수에는 제한이 없습니다.
   - Keyspace 설계 시 모든 요청이 동일한 인덱스 파티션에 대해 요청을 수행하는 시나리오를 방지해야 합니다.
   - 워크로드가 여러 인덱스 파티션에 걸쳐 잘 분산될 수 있는 높은 카디널리티 접두사를 사용하는 것이 중요합니다.

S3 Path 구조 :

```
├── Bucket_Name ──┤ ├────────── Object_Key_Name ──────────┤
example_test_bucket/partition_test/test01/2022010/example_test.csv
				  ├────────── Prefix ──────────┤├─ Object_Name ─┤
```

S3 요청 방식 : 

1. 일반적인 요청 방식:

   ![usual_s3_request](../../../../Images/S3/usual_s3_request.png)

   > 단일 Client가 순차적으로 요청

2. EMR에서 S3 요청 방식:

   ![emr_s3_request](../../../../Images/S3/emr_s3_request.png)

   > Multi node에서 단일 prefix에 parallel하게 요청하므로 일반적인 방식보다 많은 요청이 수행됩니다.

   ![emr_s3_request_partitioning](../../../../Images/S3/emr_s3_request_partitioning.png)

   > 상단 이미지 처럼 중복도가 낮은 접두사를 추가하여 요청을 여러 인덱스 파티션으로 분산하는 것을 권장합니다.
   >
   > Cardinality가 높은 Prefix 일수록 의도한 대로 Partition Index가 생성되며 Partition Index가 생성되어야 GET/HEAD  5,500 / PUT/POST/DELETE 3,500 요청이 가능해집니다.
   >
   > 또한 EMRFS에 대해 하단 옵션들 설정을 권장합니다.
   >
   > - "fs.s3.maxRetry" : 10
   >
   >   Slow Down 이슈가 발생할 경우 지속적인 Retry로 Auto Partitioning을 유도할 수 있습니다.
   >
   > - "fs.s3.retryPeriodSeconds" : 20
   >
   >   20초 정도의 유휴 시간으로 Job의 실패를 방지합니다.

---

출처 : [워크로드 특성에 따른 안전하고 효율적인 Data Lake 운영 방안](https://www.slideshare.net/awskorea/t2s1pdf)
